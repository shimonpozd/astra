# New Features Development Plan

This document outlines the plan for three new, advanced features: LLM-Powered Translation, an Enhanced Lexicon, and Text-to-Colloquial Speech ("Speechification").

---

## 1. On-Demand Translation

*   **Goal:** Allow the user to translate text fragments on demand directly within the UI, specifically in the Focus Reader and the Workbench panels.
*   **Core Logic:** To achieve high-quality, context-aware translations (e.g., into Russian), the system will send both the original Hebrew text and the existing English translation to a powerful LLM. This provides the model with maximum context, helping it understand nuanced terms.
*   **Backend Requirements:**
    *   Create a new API endpoint: `POST /api/actions/translate`.
    *   The endpoint will accept a JSON body: `{ "hebrew_text": "...", "english_text": "..." }`.
    *   This endpoint will use a specialized prompt to instruct an LLM to perform a high-quality translation based on both provided texts.
*   **Backend Status**: Implemented. New API endpoint `POST /api/actions/translate` created in `brain/main.py`. Uses `actions.translator_system` prompt.
*   **Frontend Requirements:**
    *   In the `StudyMode` and `Workbench` components, a "Translate" button or context menu option should be added to text blocks.
    *   When triggered, the frontend will send the Hebrew and English versions of the text to the `/api/actions/translate` endpoint.
    *   The UI must handle the display of the returned translation, for example, by replacing the original text while providing a button to revert to the original.

---

## 2. Enhanced Lexicon

*   **Goal:** Replace the current basic dictionary lookup with a rich, contextual linguistic analysis generated by an LLM.
*   **Core Logic:** When a user selects a word or phrase, the system will first fetch the standard dictionary definition from the Sefaria API. It will then feed this definition, along with the original word and its surrounding text (context), into an LLM to generate a more interesting and comprehensive explanation.
*   **Backend Requirements:**
    *   Create a new API endpoint: `POST /api/actions/explain-term`.
    *   Request Body: `{ "term": "...", "context_text": "..." }`.
    *   The endpoint's workflow:
        1.  Call the Sefaria Lexicon API: `GET /api/words/{term}`.
        2.  Construct a detailed prompt for an LLM that includes the term, the context in which it appeared, and the basic definition received from Sefaria.
        3.  The prompt will ask the LLM to explain what the word means in this specific context, what it could mean in other contexts, and provide other interesting linguistic details.
*   The endpoint will stream the LLM's response back to the client.
*   **Backend Status**: Implemented. New API endpoint `POST /api/actions/explain-term` created in `brain/main.py`. Uses `actions.lexicon_system` prompt.
*   **Frontend Requirements:**
    *   A new user interaction for selecting a word or phrase needs to be implemented (e.g., a right-click context menu or a pop-up on text selection).
    *   This menu will contain an "Explain Term" option which triggers a call to the `/api/actions/explain-term` endpoint.
    *   The streamed response should be displayed in the main chat window as a special, temporary message. It should be visually distinct and should **not** be added to the persistent chat history that is sent back to the LLM for conversational context.

---

## 3. Text-to-Colloquial Speech (Speechification)

*   **Goal:** Convert formal, written text into a natural, conversational audio stream, making it easier and more engaging to listen to.
*   **Core Logic:** This is a two-step process. First, an LLM rewrites the text into a spoken-word format. Second, this rewritten text is sent to the standard TTS engine.
*   **Backend Requirements:**
    *   Create a new API endpoint: `POST /api/actions/speechify`.
    *   Request Body: `{ "text": "..." }`.
    *   The endpoint's workflow:
        1.  Call an LLM with a prompt instructing it to rewrite the provided text into a more natural, conversational, and spoken style (e.g., "Rewrite this formal text as if you were explaining it in a casual lecture").
        2.  Take the LLM's rewritten text as output.
        3.  Pipe this new text to the existing TTS service (`/api/tts`).
*   Stream the resulting audio back to the client as the response.
*   **Backend Status**: Implemented. New API endpoint `POST /api/actions/speechify` created in `brain/main.py`. Uses `actions.speechify_system` prompt. Modified `tts/main.py` to include a streaming endpoint (`POST /stream`) to provide audio data to clients. Updated `brain/tts_client.py` to use this new streaming endpoint.
*   **Frontend Requirements:**
    *   Add a "Speechify" or "Listen" button to relevant text blocks (e.g., the final research draft in Study Mode, or long text passages).
    *   When clicked, the button will call the `/api/actions/speechify` endpoint.
    *   The frontend should be able to receive and play the streamed audio response.

---

## 4. Granular Context Control (New Requirement)

*   **Goal:** Allow fine-grained control over what linguistic context (Hebrew, English, or both) is sent to the LLM for different tasks, including both explicit actions (like translation) and implicit actions (like asking a question about a text).
*   **Affected Areas:**
    1.  **On-Demand Translation Action:** (As described in section 1).
    2.  **Standard Chat in Study Mode:** When a user asks a question about the text currently in focus.
*   **Configuration Requirements:**
    *   The `config/defaults.toml` file needs a new, more detailed section for these settings.
    *   **Proposed Structure:**
        ```toml
        [actions.translation]
        # Setting for the explicit "Translate" button
        # Options: "high" (sends Hebrew + English), "fast" (sends English only)
        on_demand_quality = "high"

        [actions.context]
        # Setting for the context included in normal questions during Study Mode
        # Options: "hebrew_and_english", "english_only", "hebrew_only"
        study_mode_context = "english_only"
        ```
*   **Configuration Status**: Implemented. New settings `actions.translation.on_demand_quality` and `actions.context.study_mode_context` added to `config/defaults.toml`.
*   **Backend Status**: `study_chat_stream_processor` in `brain/main.py` refactored to fetch context based on `study_mode_context` setting.
*   **Backend Requirements:**
    *   The `study_chat_stream_processor` function in `brain/main.py` must be refactored.
    *   It needs to read the new `actions.context.study_mode_context` setting from the config.
    *   Based on this setting, it must fetch the appropriate text(s) for the `discussion_ref`. This may require modifying Sefaria client functions to retrieve both Hebrew and English versions of a text simultaneously.
    *   The system prompt for the `chevruta_talmud` personality must be updated to handle receiving one or both texts.
*   **Frontend Requirements:**
    *   The "General Settings" UI (`GeneralSettings.tsx`) must be updated to include dropdown menus for these new settings, likely under a new "Actions & Context" tab or within the "LLM" tab.

---

## Architectural Note: Isolation of Actions

As requested, the **Enhanced Lexicon** and **Speechification** features will be treated as "one-shot tools." The requests and their results will not be persisted in the short-term or long-term memory of the conversational agent. The frontend state management should ensure that these interactions do not pollute the main chat history that provides context for follow-up questions.