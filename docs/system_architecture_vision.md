### **Техническое Задание: Архитектура "Интерактивного Учебного Стола"**

#### **1. Текущая Архитектура (Как работает сейчас)**

*   **Основа:** Бэкенд на FastAPI, который общается с LLM (GPT/Ollama) через OpenAI-совместимый клиент.
*   **Источник знаний:** Внешнее API Sefaria, для которого написан отказоустойчивый клиент `sefaria_client.py`.
*   **Состояние:** Сессии хранятся в Redis. Каждая сессия — это, по сути, линейный список сообщений в чате (`short_term_memory`).
*   **Логика:** Управляется почти полностью через системный промпт LLM. LLM решает, когда вызывать инструменты (`sefaria_get_text_v3`, `update_commentators_panel` и т.д.).
*   **Режимы:** Есть два основных "потока" (`flow`): `conversational` (диалог с вызовом инструментов) и `deep_research` (длительное исследование с генерацией итогового документа).

#### **2. Фундаментальные Ограничения Текущей Архитектуры**

1.  **Проблема Рекурсии:** Как вы верно заметили, логика, управляемая LLM, рекурсивна. Запрос "открой Шаббат 21а" и последующий выбор комментария "Раши на Шаббат 21а" с панели обрабатываются по одному и тому же сценарию, что вызывает зацикливание и непредсказуемое поведение.
2.  **Потеря Контекста:** Интерфейс чата линеен. Если пользователь, изучая Танах, переходит по ссылке на Талмуд, он "теряет" исходное место в Танахе. Нет простого способа вернуться назад, сохранив состояние (например, открытых на тот момент комментаторов).
3.  **Отсутствие Структуры Текста:** Система не понимает структуру документа (например, что за отрывком `23a.1` идет `23a.2`). Навигация ("дальше", "назад") примитивна и зависит от способности LLM правильно инкрементировать номер стиха.
4.  **Перегруженность LLM:** На LLM возлагается слишком много ответственности за управление состоянием и навигацией, что дорого, медленно и ненадежно.

#### **3. Предлагаемая Архитектура: Концепция "Учебного Стола"**

Вместо линейного чата предлагается внедрить концепцию "Учебного стола" — интерактивного пространства, управляемого состоянием на бэкенде, а не промптами LLM.

**Ключевые компоненты интерфейса:**

*   **3.1. "Просмотрщик Текста" (Окно Фокуса):**
    *   Центральный элемент UI, отображающий **текущий изучаемый отрывок** (например, `Shabbat 23a.2`).
    *   В нем же "приглушенно" (серым цветом или менее крупно) отображаются предыдущий и следующий отрывки (`23a.1` и `23a.3`), давая пользователю контекст.

*   **3.2. "Книжная Полка" (Панель Комментаторов):**
    *   Боковая панель, которая всегда отображает список комментаторов, релевантных **только для текста в фокусе**.

*   **3.3. "Учебный Путь" (Хлебные крошки / Стек вызовов):**
    *   Новый UI-элемент, показывающий путь углубления в текст. Например: `Bereshit 1:1` > `Shabbat 21a` > `Rashi on Shabbat 21a:1`.
    *   Клик по предыдущему элементу в этой цепочке ("Bereshit 1:1") должен "откатывать" состояние всего "стола" назад: в фокус загружается Берешит 1:1, а на "книжной полке" появляются комментаторы к нему.

*   **3.4. Чат для Обсуждений:**
    *   Чат остается, но его роль сужается: он служит для обсуждения с LLM **только того текста, который сейчас в фокусе**.

#### **4. Необходимые Изменения в Бэкенде**

1.  **Новая Структура Состояния Сессии (в Redis):**
    *   Вместо простого списка сообщений, сессия должна хранить **стек "состояний стола"** (`study_desk_stack`).
    *   Каждый элемент стека — это объект, описывающий одно состояние:
        ```json
        {
          "focus_ref": "Shabbat 21a.2",
          "context_refs": { "prev": "Shabbat 21a.1", "next": "Shabbat 21a.3" },
          "bookshelf_items": [ ...список комментаторов... ],
          "chat_history_for_focus": [ ...сообщения, относящиеся к этому фокусу... ]
        }
        ```

2.  **Новые API Эндпоинты (в `main.py`):**
    *   `POST /session/set_focus`: Принимает `tref`. Бэкенд:
        1.  Загружает текст и его соседей (`.1`, `.3`).
        2.  Загружает комментаторов для него.
        3.  Формирует новый "объект состояния стола".
        4.  **Добавляет (push) этот объект в стек** `study_desk_stack` в Redis.
        5.  Возвращает клиенту полное новое состояние для отрисовки.
    *   `POST /session/pop_focus`: Не принимает аргументов. Бэкенд:
        1.  **Удаляет (pop) верхний элемент из стека** `study_desk_stack`.
        2.  Возвращает предыдущее состояние, которое теперь стало верхним.
    *   `POST /session/chat`: Принимает `text`. Вызывает LLM для обсуждения текста, который сейчас находится в `focus_ref` **верхнего элемента стека**.

#### **5. Новая Роль LLM**

*   **LLM больше не управляет навигацией.** Эта логика переходит на бэкенд и действия пользователя. Промпт LLM упрощается до: "Ты — хеврута. Обсуждай текст, который тебе предоставляют".
*   **Проблема рекурсии решается полностью.** Клик на комментаторе на панели вызывает `POST /session/set_focus` с `ref` этого комментария. Это явное действие, а не неоднозначная команда в чате.

#### **6. Совместимость с `deepresearch`**

*   Режим `deepresearch` остается практически неизменным. Его можно рассматривать как отдельный, "тяжелый" процесс, который не использует интерактивный "Учебный стол", а генерирует итоговый документ. Эти два режима почти не пересекаются.

#### **7. Преимущества Новой Архитектуры**

*   **Надежность:** Устраняет рекурсию и непредсказуемость, перенося логику из LLM в детерминированный код бэкенда.
*   **Глубина:** Позволяет реализовать бесконечную вложенность изучения (Танах -> Талмуд -> Комментарий -> другой комментарий) с возможностью вернуться на любой уровень.
*   **Персистентность:** Сохранение стека состояний в Redis позволит пользователю продолжить учебу с того же места, где он остановился.
*   **Скорость:** Навигация ("вперед", "назад", "вернуться") становится мгновенной, так как не требует вызова LLM.
