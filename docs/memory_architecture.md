
# Архитектура и статус сервиса памяти (Memory Service)

Этот документ описывает текущую архитектуру сервиса памяти, его статус реализации и дальнейшие шаги по развитию.

---

## 1. Актуальная архитектура (гибридная модель)

Сервис памяти переведен на гибридную модель, разделяющую различные типы информации для более эффективной обработки. Память теперь состоит из двух основных компонентов:

1.  **D/I-Graph (Диалог/Намерения) на Neo4j:** Графовая база данных, которая хранит структуру и семантику диалогов.
2.  **K-Graph (Знания) на Qdrant:** Векторная база данных, предназначенная для хранения и поиска фактов, знаний и ассоциаций.

### Логическая диаграмма

```
+------------------------------------+
|               brain                |
|         (LLM + Core Logic)         |
+-----------------+------------------+
                  | (1. Get Context)
                  | (3. Update Dialog)
                  v
+------------------------------------+
|          memory (service)          |
+-----------------+------------------+
| (2a. Get D/I)   | (2b. Get K)      |
v                 v                  v
+-----------------+------------------+
|    D/I-Graph    |     K-Graph      |
|     (Neo4j)     |    (Qdrant)      |
+-----------------+------------------+
```

### Поток данных при генерации ответа:

1.  **`brain`** перед вызовом LLM запрашивает контекст у **`memory`**. 
2.  **`memory`** обращается:
    a.  К **Neo4j** для получения последних реплик и актуальных тем диалога (D/I-Graph).
    b.  К **Qdrant** для получения фактов, связанных с этими темами (K-Graph).
3.  **`memory`** собирает из полученных данных `pointer-context` и отдает его в `brain`.
4.  **`brain`** использует этот контекст в промпте для LLM.
5.  После каждой реплики **`brain`** отправляет событие в **`memory`** для обновления графа диалога в Neo4j.

---

## 2. Текущий статус реализации

На данный момент реализован значительный объем функционала, соответствующий техзаданию.

**Что сделано и работает:**

*   **Базы данных:** Подняты и сконфигурированы контейнеры `Neo4j` и `Qdrant`.
*   **Миграция данных:** Создан и отлажен скрипт `backfill.py`, который успешно переносит исторические данные из `koyzah/*.csv` в графовую базу Neo4j.
*   **Реализованы все эндпоинты сервиса `memory`:**
    *   `POST /graph/backfill`: Запускает процесс миграции данных.
    *   `POST /graph/dialog/update`: Принимает события диалога и обновляет граф в Neo4j.
    *   `GET /graph/context`: Собирает и отдает `pointer-context`, используя данные из Neo4j и временную реализацию K-Graph.
    *   `GET /graph/next_steps`: Предлагает проактивные шаги на основе графа переходов интентов и управляет их кулдауном через Redis.
*   **Интеграция с `brain`:** Сервис `brain` полностью интегрирован с новыми эндпоинтами `memory`. Он запрашивает контекст перед генерацией ответа и отправляет обновления после каждой реплики.

---

## 3. Дальнейшие шаги и улучшения

Несмотря на полную работоспособность базового сценария, в ходе реализации были сделаны некоторые упрощения. Для полноценного завершения системы необходимо выполнить следующие доработки:

1.  **Реализовать полноценный K-Graph в Qdrant.**
    *   **Текущее состояние:** Факты для K-Graph берутся напрямую из `concepts.csv` без использования векторов.
    *   **Что нужно сделать:** При миграции данных (`backfill`) необходимо создавать эмбеддинги для концептов и загружать их в Qdrant. Эндпоинт `/graph/context` нужно переключить на реальный векторный поиск по темам в Qdrant для извлечения фактов.

2.  **Внедрить модель извлечения тем и интентов в `brain`.**
    *   **Текущее состояние:** При обновлении графа (`/dialog/update`) `brain` отправляет заглушки вместо реальных тем и интентов для реплик.
    *   **Что нужно сделать:** Разработать или интегрировать механизм (например, отдельный вызов LLM или классификационная модель), который будет анализировать текст реплики и извлекать из нее список упомянутых тем и определять намерение пользователя.

3.  **Пересмотреть механизм хранения сессий.**
    *   **Текущее состояние:** ID сессии (`session_id`) генерируется при каждом запуске `brain` и не сохраняется между перезапусками.
    *   **Что нужно сделать:** Продумать и реализовать механизм постоянных сессий, если требуется сохранять историю диалогов с одним и тем же пользователем между запусками приложения.

4.  **Продумать синергию двух систем памяти.**
    *   **Текущее состояние:** `brain` использует графовую память для сборки `pointer-context`, а старую LTM (`mem0`) — для сохранения полной истории диалога и для поиска по ней через `tool-calling`.
    *   **Что нужно сделать:** Определить четкие границы ответственности каждой системы. Возможно, `pointer-context` следует обогащать не только фактами из K-Graph, но и результатами семантического поиска из LTM (`mem0`), чтобы дать LLM еще более полную картину.
