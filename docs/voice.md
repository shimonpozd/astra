## –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (–Ω–∞ 2025-09-18)

### –ó–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (–≤—Å–µ —Ñ–∞–∑—ã –ø–ª–∞–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã)
- **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (Phase 5.1)**:
  - –ë—ç–∫–∞–ø—ã: voice-in_backup, stt_backup —Å–æ–∑–¥–∞–Ω—ã.
  - –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã websockets, noisereduce, pydub, asyncio-throttle, httpx, psutil –≤ venv'–∞—Ö voice-in –∏ stt.
  - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: .env —Ñ–∞–π–ª—ã –≤ voice-in –∏ stt —Å —Ñ–ª–∞–≥–∞–º–∏ (VOICE_STREAMING_ENABLED=false, VOICE_INTERRUPT_ENABLED=false, GPU_ENABLED=true, WHISPER_MODEL_SIZE=large).
  - –ú–µ—Ç—Ä–∏–∫–∏: –ë–∞–∑–æ–≤–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ VAD/STT –≤ logger.info.

- **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è VAD (Phase 5.2)**:
  - –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: VAD_THRESHOLD=0.45, THRESH_SPEECH=0.55, THRESH_SILENCE=0.40, MIN_SILENCE_MS=800, SPEECH_PAD_MS=80, CHUNK_SAMPLES=512.
  - –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞: calibrate_vad_thresholds() –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç 5s —Ç–∏—à–∏–Ω—ã, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ noise_floor, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ vad_calibration.json. –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è (run_calibration_async).
  - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è: –í—ã–∑–æ–≤ –≤ startup, update VAD iterator.

- **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Whisper (Phase 5.3)**:
  - –ú–æ–¥–µ–ª—å: –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ large-v2 (medium-v3 –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —Å–∫–∞—á–∞–π—Ç–µ –¥–ª—è 1.5GB VRAM —ç–∫–æ–Ω–æ–º–∏–∏).
  - –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: beam_size=1, vad_filter=False, temperature=0.0 –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞.
  - GPU: torch.cuda.empty_cache() –ø–æ—Å–ª–µ transcribe, compute_type="float16".
  - –ú–µ—Ç—Ä–∏–∫–∏: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ total STT processing time.

- **–°–∏—Å—Ç–µ–º–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ (Phase 5.4)**:
  - WebSocket –≤ voice-in: /ws/voice (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç status).
  - –õ–æ–≥–∏–∫–∞ –≤ vad_pipeline: –û—Ç–ø—Ä–∞–≤–∫–∞ —á–∞–Ω–∫–æ–≤ –∫–∞–∂–¥—ã–µ 2s (CHUNK_DURATION_MS) —á–µ—Ä–µ–∑ send_stream_chunk (websockets.connect to /ws/stt).
  - STT —Å—Ç—Ä–∏–º–∏–Ω–≥: /ws/stt –≤ stt/main.py, process_partial_audio –¥–ª—è partial transcription (–∫–∞–∂–¥—ã–µ 32k samples), –æ—Ç–ø—Ä–∞–≤–∫–∞ JSON {type: "partial", text, confidence}.
  - –§–ª–∞–≥–∏: STREAMING_ENABLED=false (–≤–∫–ª—é—á–∏—Ç–µ –¥–ª—è —Ç–µ—Å—Ç–∞).

- **–°–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–±–∏–≤–∞–Ω–∏—è (Phase 5.5)**:
  - StateManager: Enum VoiceState (LISTENING, PROCESSING, SPEAKING, INTERRUPTED), transition(event) —Å lock.
  - DuplexAudioManager: –û—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫ monitor_interrupts() (10ms polling), –¥–µ—Ç–µ–∫—Ü–∏—è prob > INTERRUPT_THRESHOLD=0.7 –≤–æ –≤—Ä–µ–º—è SPEAKING.
  - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è: state.is_speaking=true –≤–æ –≤—Ä–µ–º—è TTS, Redis pub/sub "astra:tts_interrupt" –¥–ª—è stop.
  - Grace period: 300ms min duration, state transition to INTERRUPTED -> LISTENING.

- **–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ (Phase 5.6)**:
  - –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: noisereduce.reduce_noise, pydub.effects.normalize, high-pass filter (80Hz) –ø–µ—Ä–µ–¥ VAD.
  - Adaptive thresholds: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —à—É–º–∞.
  - Multi-language: –ê–≤—Ç–æ-–¥–µ—Ç–µ–∫—Ç –≤ Whisper, fallback "ru".

- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏ (Phase 5.7)**:
  - –õ–æ–≥–∏: VAD duration, STT processing, chunks_processed, speech_detected_count, confidence.
  - Health check: /health (status, uptime, memory_mb, cpu_percent, vad_ready).
  - Config validation: validate_config() –≤ startup (CHUNK_SAMPLES 160-1024, MIN_SILENCE_MS 200-5000).
  - Error recovery: consecutive_errors >10 -> stop pipeline.
  - Memory: voiced_frames.clear(), torch.cuda.empty_cache().

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (Phase 5.3, 5.7)
- **–¢–µ–∫—É—â–∏–µ –ª–æ–≥–∏**: VAD –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç —Ä–µ—á—å (1.57s –¥–ª—è 51KB), STT –ø–æ–ª—É—á–∞–µ—Ç (51KB), –Ω–æ –æ—à–∏–±–∫–∏ –≤ torch import (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ).
- **–¶–µ–ª–∏**: –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å 3-7s, interrupt <500ms, confidence >0.8, GPU <80%.
- **Load test**: 3 concurrent streams, 20 –º–∏–Ω —Å–µ—Å—Å–∏–∏.
- **Deploy**: Docker-compose.yml —Å health checks, blue-green.

### –û—Å—Ç–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ –∏ –¥–µ–ø–ª–æ–π)
1. **–°–∫–∞—á–∞—Ç—å medium –º–æ–¥–µ–ª—å**: `python -m faster_whisper.download --model medium`, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å WHISPER_MODEL_SIZE=medium.
2. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Brain/TTS**: –ü–æ–¥–∫–ª—é—á–∏—Ç—å Redis listener –¥–ª—è "astra:tts_interrupt", TTS playback —Å state.is_speaking=true.
3. **–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç**:
   - POST /start –Ω–∞ 7010.
   - –ì–æ–≤–æ—Ä–∏—Ç–µ - –ø—Ä–æ–≤–µ—Ä–∫–∞ VAD duration <2s, STT response <5s.
   - –°—Ç—Ä–∏–º–∏–Ω–≥: VOICE_STREAMING_ENABLED=true, –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ ws://7010/ws/voice, partial text –∫–∞–∂–¥—ã–µ 2s.
   - –ü–µ—Ä–µ–±–∏–≤–∞–Ω–∏–µ: –í–æ –≤—Ä–µ–º—è TTS –≥–æ–≤–æ—Ä–∏—Ç—å –≥—Ä–æ–º–∫–æ, –ø—Ä–æ–≤–µ—Ä–∫–∞ "Interrupt detected", state transition.
   - Health: GET /health, /status - –º–µ—Ç—Ä–∏–∫–∏.
4. **–î–µ–ø–ª–æ–π**: Docker-compose up, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ 24—á (latency, success rate >90%).
5. **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: README —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –ø–æ –∑–∞–ø—É—Å–∫—É, env vars, API endpoints.

–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ production. –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ —Å Brain/TTS, –∏ –µ—Å–ª–∏ –≤—Å—ë OK, –∑–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!
–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ production. –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ —Å Brain/TTS, –∏ –µ—Å–ª–∏ –≤—Å—ë OK, –∑–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!
## –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π

### üéØ –§–ê–ó–ê 1: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í–´–°–û–ö–ò–ô)
#### 1.1 Streaming STT –≤–º–µ—Å—Ç–æ batch
- **–¢–µ–∫—É—â–∏–π**: –ü–æ–ª–Ω—ã–π payload –≤ `/stt` –ø–æ—Å–ª–µ —Ç–∏—à–∏–Ω—ã.
- **–ò–∑–º–µ–Ω–µ–Ω–∏—è**:
  - –í voice-in: –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å `vad_pipeline()` ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —á–∞–Ω–∫–∏ –∫–∞–∂–¥—ã–µ 2000ms —Ä–µ—á–∏ (VOICE_CHUNK_DURATION_MS).
  - –õ–æ–≥–∏–∫–∞: –ù–∞–∫–æ–ø–∏—Ç—å voiced_frames –¥–æ chunk timeout –∏–ª–∏ speech end, –æ—Ç–ø—Ä–∞–≤–∏—Ç—å via WebSocket.
  - –í STT: –ù–æ–≤—ã–π `/stt/stream` (WebSocket). –ü—Ä–∏–Ω–∏–º–∞—Ç—å —á–∞–Ω–∫–∏, append –∫ buffer, transcribe partial (Whisper –Ω–∞ updated audio).
  - –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è: WebSocket –¥–ª—è bidirectional (chunks ‚Üí partial text).
  - **–ö–æ–¥–æ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è**:
    - Voice-in: –î–æ–±–∞–≤–∏—Ç—å `websocket` import, –Ω–æ–≤—ã–π endpoint `@app.websocket("/ws/voice")`.
    - STT: –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ, `async def websocket_endpoint(websocket: WebSocket)`; –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `asyncio.Queue` –¥–ª—è buffer.
  - **–û–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç**: Partial results —á–µ—Ä–µ–∑ 2-3s, –ø–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø–æ —Ç–∏—à–∏–Ω–µ.

#### 1.2 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è VAD –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ voice-in/main.py**:
  ```python
  MIN_SILENCE_MS = 800      # –ë—ã—Å—Ç—Ä–µ–µ –¥–µ—Ç–µ–∫—Ç –æ–∫–æ–Ω—á–∞–Ω–∏—è
  SPEECH_PAD_MS = 80        # –ú–µ–Ω—å—à–µ padding
  CHUNK_SAMPLES = 256       # –ú–µ–Ω—å—à–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (16ms chunks)
  VAD_THRESHOLD = 0.45      # –ë–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π
  THRESH_SPEECH = 0.55      # –ë—ã—Å—Ç—Ä–µ–µ –∞–∫—Ç–∏–≤–∞—Ü–∏—è
  THRESH_SILENCE = 0.40     # –ú–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
  ```
- **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ**: –î–æ–±–∞–≤–∏—Ç—å adaptive calibration –ø—Ä–∏ startup (–∞–Ω–∞–ª–∏–∑ 5s silence).

#### 1.3 –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
- **–ò–∑–º–µ–Ω–µ–Ω–∏—è**:
  - –í STT: –ü–æ—Å–ª–µ partial transcribe, async call to Brain `/chat/voice?partial=true`.
  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `asyncio.create_task` –¥–ª—è preload LLM (e.g., send partial prompt).
  - Pipeline: STT partial ‚Üí asyncio.gather(STT full, LLM prep) ‚Üí TTS.
  - –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞: –ó–∞–≥—Ä—É–∂–∞—Ç—å LLM/Whisper –≤ shared memory –ø—Ä–∏ startup.
- **–ö–æ–¥**: –í stt/main.py –¥–æ–±–∞–≤–∏—Ç—å `import asyncio`; `async def parallel_pipeline(partial_text): ...`.

#### 1.4 Whisper –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- **–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ stt/main.py**:
  ```python
  # –í initialize_stt_client
  state.stt_client = WhisperModel(MODEL_PATH, device=DEVICE, compute_type="float16")
  # –í transcribe
  segments, info = state.stt_client.transcribe(audio_buffer, 
      beam_size=1, 
      model_size="medium",  # –í–º–µ—Å—Ç–æ large
      vad_filter=False,
      temperature=0.0,
      language=FORCED_LANGUAGE
  )
  ```
- **–î–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Whisper's chunked mode (if available) –∏–ª–∏ manual buffer append.

#### 1.5 –°–∏—Å—Ç–µ–º–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –£–±—Ä–∞—Ç—å verbose logging: –í logging_utils –¥–æ–±–∞–≤–∏—Ç—å level="INFO" –¥–ª—è prod.
- Timeouts: –í requests.post ‚Üí timeout=5s.
- Threads: –£–≤–µ–ª–∏—á–∏—Ç—å `concurrent.futures.ThreadPoolExecutor(max_workers=4)`.
- Connection pooling: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `httpx.AsyncClient` —Å limits.
- Keep-alive: –í FastAPI –¥–æ–±–∞–≤–∏—Ç—å middleware –¥–ª—è persistent connections.

**–¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏**: –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å 3-7s (speech start ‚Üí response start).

### üîÑ –§–ê–ó–ê 2: –°–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–±–∏–≤–∞–Ω–∏—è (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í–´–°–û–ö–ò–ô)
#### 2.1 Continuous VAD
- **–ò–∑–º–µ–Ω–µ–Ω–∏—è**:
  - –ù–æ–≤—ã–π –∫–ª–∞—Å—Å –≤ voice-in:
    ```python
    class DuplexAudioManager:
        def __init__(self):
            self.input_stream = None  # pyaudio input
            self.output_stream = None # pyaudio output –¥–ª—è TTS
            self.vad_monitor = None   # Separate thread –¥–ª—è VAD
            self.is_speaking = False
            self.lock = threading.Lock()
        
        def start_monitoring(self):
            self.vad_monitor = threading.Thread(target=self._vad_loop, daemon=True)
            self.vad_monitor.start()
        
        def _vad_loop(self):
            # Continuous read from input_stream, apply VAD
            while True:
                chunk = self.input_stream.read(CHUNK_SAMPLES)
                prob = self.vad_model(chunk)
                if self.is_speaking and prob > INTERRUPT_THRESHOLD:
                    self.handle_interrupt()
    ```
  - Audio devices: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ input/output –∏–ª–∏ AEC (Acoustic Echo Cancellation via webrtcvad –∏–ª–∏ speex).

#### 2.2 Interrupt Detection
- **–õ–æ–≥–∏–∫–∞**:
  - –í–æ –≤—Ä–µ–º—è SPEAKING: VAD_monitor –∞–∫—Ç–∏–≤–µ–Ω.
  - –ü—Ä–∏ prob >= 0.70 –Ω–∞ 300ms: –í—ã–∑–≤–∞—Ç—å `handle_interrupt()` ‚Äî stop TTS (e.g., via brain API `/tts/stop`), clear queues, set state=INTERRUPTED.
- **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**:
  ```python
  INTERRUPT_THRESHOLD = 0.70
  INTERRUPT_MIN_DURATION = 300  # ms
  TTS_STOP_TIMEOUT = 100
  ```
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è**: –û—Ç–ø—Ä–∞–≤–∏—Ç—å interrupt signal –≤ Brain via Redis pub/sub (`astra:interrupt`).

#### 2.3 State Management
- **Enum –≤ voice-in**:
  ```python
  from enum import Enum
  class VoiceState(Enum):
      LISTENING = 1
      PROCESSING = 2
      SPEAKING = 3
      INTERRUPTED = 4
  
  class StateManager:
      def __init__(self):
          self.current_state = VoiceState.LISTENING
          # Transitions logic
      def transition(self, event):
          if self.current_state == VoiceState.SPEAKING and event == "interrupt_detected":
              self.current_state = VoiceState.INTERRUPTED
              # Clear TTS, start listening
  ```
- Transitions: –ö–∞–∫ –≤ –¢–ó, —Å callbacks.

#### 2.4 Grace Period
- –ü–æ—Å–ª–µ SPEAKING: 200ms delay –ø–µ—Ä–µ–¥ LISTENING.
- Echo cancellation: –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å `pydub.effects` –∏–ª–∏ `noisereduce` –¥–ª—è subtract TTS from input.
- Adaptive: –ö–∞–ª–∏–±—Ä–æ–≤–∞—Ç—å threshold –Ω–∞ background noise (initial 3s analysis).

**–¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏**: Interrupt reaction <500ms.

### üéß –§–ê–ó–ê 3: –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –°–†–ï–î–ù–ò–ô)
#### 3.1 Audio Preprocessing
- **–¶–µ–ø–æ—á–∫–∞ –≤ voice-in –ø–µ—Ä–µ–¥ VAD**:
  ```python
  import noisereduce as nr
  from pydub import AudioSegment
  from pydub.effects import normalize, compress_dynamic_range
  
  def preprocess_audio(chunk: np.array) -> np.array:
      # Noise reduction
      reduced = nr.reduce_noise(y=chunk, sr=RATE)
      # To pydub for normalization/compress
      audio_seg = AudioSegment(
          reduced.tobytes(),
          frame_rate=RATE,
          sample_width=2,
          channels=1
      )
      audio_seg = normalize(audio_seg)
      audio_seg = compress_dynamic_range(audio_seg, threshold=-20.0, ratio=4.0, attack=5.0, release=50.0)
      # High-pass filter: audio_seg.high_pass_filter(80)
      return np.array(audio_seg.get_array_of_samples(), dtype=np.int16)
  ```
- –ü—Ä–∏–º–µ–Ω—è—Ç—å –≤ vad_pipeline loop.

#### 3.2 Adaptive Thresholds
- –ü—Ä–∏ startup: Capture 5s silence, compute noise floor.
- Dynamic: Adjust VAD_THRESHOLD += noise_level * 0.1.
- –°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ config.json –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏.

#### 3.3 Multi-language Support
- –í STT: –£–±—Ä–∞—Ç—å FORCED_LANGUAGE, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å auto-detect.
- Fallback: –ï—Å–ª–∏ confidence <0.8, retry —Å "ru".
- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: LangID model (e.g., langdetect) –Ω–∞ partial text.

**–¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏**: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ accuracy >95%, –º–µ–Ω—å—à–µ –æ—à–∏–±–æ–∫ –Ω–∞ —à—É–º.

### üñ•Ô∏è –§–ê–ó–ê 4: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è RTX 3060 12GB (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í–´–°–û–ö–ò–ô)
#### 4.1 GPU Memory Management
- **–ú–æ–¥–µ–ª–∏**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Whisper "medium" (1.5GB VRAM) –≤–º–µ—Å—Ç–æ "large" (3GB+). Silero VAD (~50MB) –∏ TTS –º–æ–¥–µ–ª–∏ (e.g., XTTS ~2GB) –∑–∞–≥—Ä—É–∂–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ.
- **Batch Size**: –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å concurrent streams –¥–æ 2-3 (VOICE_MAX_CONCURRENT_STREAMS=3). –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `torch.cuda.empty_cache()` –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ transcribe.
- **Compute Type**: float16 –¥–ª—è –≤—Å–µ—Ö CUDA –æ–ø–µ—Ä–∞—Ü–∏–π. –í faster_whisper: `compute_type="float16"`. –î–ª—è LLM (–µ—Å–ª–∏ –≤ Brain): `torch.float16`.
- **–ö–æ–¥ –≤ STT**:
  ```python
  import torch
  # –ü–æ—Å–ª–µ transcribe
  torch.cuda.empty_cache()
  ```

#### 4.2 CPU/GPU Load Balancing
- **VAD –∏ Preprocessing**: –î–µ—Ä–∂–∞—Ç—å –Ω–∞ CPU (Silero CPU-friendly). PyAudio threads –Ω–∞ CPU cores (4-6 workers).
- **STT/LLM**: –ü–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞ GPU. –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å `nvidia-smi` ‚Äî —Ü–µ–ª—å <80% utilization –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è thermal throttling.
- **TTS**: –ï—Å–ª–∏ XTTS, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU inference —Å batch=1. –î–ª—è interrupt: GPU-accelerated stop (clear tensors).
- **Async Queues**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `asyncio.Queue` —Å maxsize=5 –¥–ª—è –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–∏ —á–∞–Ω–∫–æ–≤, —á—Ç–æ–±—ã –Ω–µ overload GPU.

#### 4.3 System-Level Optimizations
- **Drivers**: –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å CUDA 11.8+ –∏ cuDNN 8.6 –¥–ª—è RTX 30-series. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å `torch==2.0.1+cu118`.
- **Power Management**: –í Windows: High Performance mode –¥–ª—è GPU. –û—Ç–∫–ª—é—á–∏—Ç—å unnecessary background processes.
- **Memory Swapping**: –£–≤–µ–ª–∏—á–∏—Ç—å pagefile –¥–æ 16GB (SSD). –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å RAM usage ‚Äî —Ü–µ–ª—å <8GB total (12GB VRAM free for peaks).
- **Cooling**: –î–ª—è long sessions ‚Äî –¥–æ–±–∞–≤–∏—Ç—å fan curve via MSI Afterburner. Latency spikes –æ—Ç overheating.
- **Fallbacks**: –ï—Å–ª–∏ GPU OOM, switch to CPU mode (Whisper "base" model, ~500MB RAM). Env var: `GPU_ENABLED=true/false`.

#### 4.4 Performance Monitoring
- –î–æ–±–∞–≤–∏—Ç—å –≤ `/metrics`: GPU mem usage via `torch.cuda.memory_allocated()`, CPU via `psutil`.
- Benchmarks: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ 3060 ‚Äî —Ü–µ–ª—å 3-5s latency –ø—Ä–∏ 1080p background load.
- Scaling: –ï—Å–ª–∏ multiple agents, limit to 1 GPU session.

**–û–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç**: –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–∞ 3060 –±–µ–∑ crashes, latency <7s even –ø–æ–¥ load.

### üìã –§–ê–ó–ê 5: –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø–ª–∞–Ω –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô)
–¶–µ–ª—å: –í–Ω–µ–¥—Ä—è—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ, —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–ª–æ–º–∫–∏ —Å–∏—Å—Ç–µ–º—ã. –ö–∞–∂–¥–∞—è –ø–æ–¥—Ñ–∞–∑–∞ –≤–∫–ª—é—á–∞–µ—Ç: –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞, unit/integration —Ç–µ—Å—Ç—ã, rollback –ø–ª–∞–Ω. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å git branches (e.g., `feature/phase1.1`). –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ staging setup –ø–µ—Ä–µ–¥ prod.

#### 5.1 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (1-2 –¥–Ω—è)
- **–®–∞–≥–∏**:
  1. –°–æ–∑–¥–∞—Ç—å backup —Ç–µ–∫—É—â–∏—Ö voice-in/ –∏ stt/ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π.
  2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–æ–≤—ã–µ dependencies (websockets, noisereduce, etc.) –≤ virtualenv. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å import –±–µ–∑ –∑–∞–ø—É—Å–∫–∞.
  3. –î–æ–±–∞–≤–∏—Ç—å .env config —Å —Ñ–ª–∞–≥–∞–º–∏ (VOICE_STREAMING_ENABLED=false –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é).
  4. –í–Ω–µ–¥—Ä–∏—Ç—å basic metrics logging (time.perf_counter() –≤ vad_pipeline –∏ /stt).
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å–∏—Å—Ç–µ–º—É ‚Äî —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –±–∞–∑–æ–≤—ã–π VAD+STT —Ä–∞–±–æ—Ç–∞–µ—Ç (latency ~30s ok).
- **Rollback**: –ï—Å–ª–∏ breaks ‚Äî revert requirements.txt –∏ .env.
- **–ú–µ—Ç—Ä–∏–∫–∏**: Baseline latency measurement (record 10 —Ñ—Ä–∞–∑).

#### 5.2 –§–∞–∑–∞ 1.1-1.2: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è VAD –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (3-4 –¥–Ω—è)
- **–®–∞–≥–∏**:
  1. –í voice-in/main.py: –ò–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (MIN_SILENCE_MS=800, etc.). –î–æ–±–∞–≤–∏—Ç—å adaptive calibration (5s silence analysis).
  2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å VAD standalone: –ó–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é —Ä–µ—á–∏ (–±–µ–∑ STT).
  3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å —Ç–µ–∫—É—â–∏–º /stt ‚Äî –∏–∑–º–µ—Ä–∏—Ç—å latency reduction (—Ü–µ–ª—å: 15-20s).
  4. –î–æ–±–∞–≤–∏—Ç—å GPU checks: `torch.cuda.is_available()` –≤ startup, fallback to CPU if false.
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: Unit tests –¥–ª—è VAD (mock audio chunks). End-to-end: 20 —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–∑, average latency <20s.
- **Rollback**: Git revert –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, disable adaptive flag.
- **–†–∏—Å–∫–∏**: False positives –≤ VAD ‚Äî –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å logs.

#### 5.3 –§–∞–∑–∞ 1.3-1.5 + 4: –°–∏—Å—Ç–µ–º–Ω—ã–µ –∏ GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (4-5 –¥–Ω–µ–π)
- **–®–∞–≥–∏**:
  1. –í STT: Switch to "medium" model, add torch.cuda.empty_cache(). –£–º–µ–Ω—å—à–∏—Ç—å timeouts.
  2. –î–æ–±–∞–≤–∏—Ç—å async –≤ STT notify_downstream (asyncio –¥–ª—è Brain call).
  3. –í–Ω–µ–¥—Ä–∏—Ç—å ThreadPoolExecutor(max_workers=4). Connection pooling via httpx.
  4. –î–æ–±–∞–≤–∏—Ç—å /metrics endpoint —Å GPU/CPU stats (psutil, torch.cuda).
  5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ load: 3 concurrent sessions via script.
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: Stress test (nvidia-smi monitoring). Latency <10s, no OOM.
- **Rollback**: Revert model size, remove async if conflicts.
- **–†–∏—Å–∫–∏**: GPU overload ‚Äî limit concurrent via env var.

#### 5.4 –§–∞–∑–∞ 1.1 Streaming (5-7 –¥–Ω–µ–π)
- **–®–∞–≥–∏**:
  1. –í voice-in: –î–æ–±–∞–≤–∏—Ç—å WebSocket /ws/voice. –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å vad_pipeline –¥–ª—è chunk sending –∫–∞–∂–¥—ã–µ 2s.
  2. –í STT: –î–æ–±–∞–≤–∏—Ç—å /stt/stream WebSocket. Implement partial buffer (append chunks, transcribe on timer).
  3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å: Voice-in ‚Üí STT stream ‚Üí partial to Brain (?partial=true).
  4. –î–æ–±–∞–≤–∏—Ç—å VOICE_STREAMING_ENABLED flag ‚Äî –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é false, –¥–ª—è A/B testing.
  5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å streaming: Real-time partial text, full latency <7s.
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: WebSocket client test (e.g., websocket-client lib). Measure partial latency (2-3s).
- **Rollback**: Disable flag, fallback to HTTP /stt.
- **–†–∏—Å–∫–∏**: WebSocket stability ‚Äî add reconnect logic.

#### 5.5 –§–∞–∑–∞ 2: Interrupt System (7-10 –¥–Ω–µ–π)
- **–®–∞–≥–∏**:
  1. –í voice-in: Implement DuplexAudioManager (separate input/output streams).
  2. –î–æ–±–∞–≤–∏—Ç—å StateManager Enum –∏ transitions.
  3. Implement interrupt detection: VAD monitor thread –≤–æ –≤—Ä–µ–º—è SPEAKING.
  4. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å Brain: Redis pub/sub –¥–ª—è /tts/stop signal.
  5. –î–æ–±–∞–≤–∏—Ç—å grace period (200ms) –∏ basic echo subtract (noisereduce on input).
  6. –í–Ω–µ–¥—Ä–∏—Ç—å VOICE_INTERRUPT_ENABLED flag.
  7. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å: Simulate interrupt (play TTS, speak over), check <500ms reaction.
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: Manual hardware test (headset). Unit –¥–ª—è state transitions.
- **Rollback**: Disable interrupt flag, remove new threads.
- **–†–∏—Å–∫–∏**: Echo issues ‚Äî test on different mics. Thread deadlocks ‚Äî add locks.

#### 5.6 –§–∞–∑–∞ 3 + 4.4: Quality –∏ Monitoring (3-4 –¥–Ω—è)
- **–®–∞–≥–∏**:
  1. –í voice-in: –î–æ–±–∞–≤–∏—Ç—å preprocess_audio (noise_reduction, normalize) –ø–µ—Ä–µ–¥ VAD.
  2. Implement adaptive thresholds (save to config.json).
  3. –í STT: Auto-detect language, fallback to "ru".
  4. –†–∞—Å—à–∏—Ä–∏—Ç—å /metrics: Latency histograms, interrupt counters, SNR.
  5. Final GPU tuning: Fallback to CPU if VRAM >10GB.
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: Accuracy test (WER on noisy audio). Multi-lang samples.
- **Rollback**: Disable preprocessing flags.
- **–†–∏—Å–∫–∏**: Preprocessing latency ‚Äî profile with cProfile.

#### 5.7 –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏ Prod Rollout (2-3 –¥–Ω—è)
- **–®–∞–≥–∏**:
  1. End-to-end test: Full pipeline (VAD ‚Üí STT stream ‚Üí Brain ‚Üí TTS ‚Üí Interrupt).
  2. Load test: 10-20 min sessions, monitor nvidia-smi/psutil.
  3. Deploy: Use docker-compose —Å health checks. Blue-green deployment.
  4. Monitor first 24h: Logs –¥–ª—è anomalies.
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: Automated e2e script (pyaudio simulate). User acceptance.
- **Rollback**: Revert to baseline branch.
- **–ú–µ—Ç—Ä–∏–∫–∏**: Final: Latency 3-7s, interrupt success >90%, GPU <80% util.

**–û–±—â–∞—è timeline**: 25-35 –¥–Ω–µ–π. –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–µ checkpoints. –í—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å git commits –∏ PR reviews.

### üîß –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –î–ï–¢–ê–õ–ò –†–ï–ê–õ–ò–ó–ê–¶–ò–ò
#### 4.1 –ù–æ–≤—ã–µ Dependencies
–û–±–Ω–æ–≤–∏—Ç—å requirements.txt (voice-in –∏ stt):
```
websockets>=11.0
asyncio-throttle>=1.0
soundfile>=0.12
noisereduce>=3.0
pydub>=0.25
httpx>=0.25  # –î–ª—è async HTTP
redis>=5.0  # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ
torch>=2.0.1  # –° CUDA support
psutil>=5.9  # –î–ª—è monitoring
```

#### 4.2 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
- **Voice-In**: –î–æ–±–∞–≤–∏—Ç—å DuplexAudioManager, WebSocket, StateManager. –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å vad_pipeline –¥–ª—è stream.
- **STT**: –î–æ–±–∞–≤–∏—Ç—å streaming endpoint, partial buffer. Async notify to Brain.
- **–û–±—â–µ–µ**: Redis –¥–ª—è cross-service signals (interrupt, partials).

#### 4.3 Configuration
–î–æ–±–∞–≤–∏—Ç—å .env:
```
# Performance
VOICE_STREAMING_ENABLED=true
VOICE_CHUNK_DURATION_MS=2000
VOICE_MAX_CONCURRENT_STREAMS=3

# Interrupt
VOICE_INTERRUPT_ENABLED=true
VOICE_INTERRUPT_THRESHOLD=0.70
VOICE_INTERRUPT_MIN_DURATION=300

# Audio
VOICE_NOISE_REDUCTION=true
VOICE_AUDIO_NORMALIZATION=true
VOICE_ADAPTIVE_THRESHOLDS=true
WHISPER_MODEL_SIZE=medium

# GPU
GPU_ENABLED=true
CUDA_VISIBLE_DEVICES=0
MAX_GPU_MEMORY_GB=10
```

#### 4.4 Monitoring & Metrics
- –í–Ω–µ–¥—Ä–∏—Ç—å Prometheus –∏–ª–∏ simple logging:
  - Latency: time.perf_counter() –Ω–∞ key points (speech_start ‚Üí response_start).
  - Interrupts: Counter –¥–ª—è success/fail.
  - STT: Log confidence scores.
  - System: psutil –¥–ª—è CPU/Mem, torch.cuda –¥–ª—è GPU.
- Endpoint `/metrics` –≤ –∫–∞–∂–¥–æ–º —Å–µ—Ä–≤–∏—Å–µ.

## –†–∏—Å–∫–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- **–†–∏—Å–∫–∏**: Echo –≤ duplex ‚Äî –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ hardware. Whisper streaming –Ω–µ native ‚Äî manual buffering –º–æ–∂–µ—Ç leak mem. GPU OOM –Ω–∞ long sessions.
- **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**: Brain/TTS –¥–æ–ª–∂–Ω—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å partials –∏ stop. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ RTX 3060 (float16 ok).
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: Unit –¥–ª—è VAD/Interrupt, end-to-end latency measurement. Load test —Å 3 concurrent streams. GPU stress test via nvidia-smi.

–≠—Ç–æ—Ç –ø–ª–∞–Ω —Ä–∞—Å—à–∏—Ä—è–µ—Ç –¢–ó —Å code-specific –¥–µ—Ç–∞–ª—è–º–∏ –∏ hardware –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è RTX 3060. –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: 2-3 –Ω–µ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é (–§–∞–∑–∞ 1+2+4), 1 –Ω–µ–¥–µ–ª—è –Ω–∞ –§–∞–∑—É 3.
